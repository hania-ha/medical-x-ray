{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73017,
     "status": "ok",
     "timestamp": 1759394863223,
     "user": {
      "displayName": "hania fatima",
      "userId": "05387605373657882009"
     },
     "user_tz": -300
    },
    "id": "_mtV7TvnuL_H",
    "outputId": "9b538798-414d-4c9d-a9a7-06b0eaeed16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.8.3)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
      "Collecting pi-heif<2 (from roboflow)\n",
      "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pillow-avif-plugin<2 (from roboflow)\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.3)\n",
      "Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.12.0.88\n",
      "    Uninstalling opencv-python-headless-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.9\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in X-ray_dataset-1 to folder:: 100%|██████████| 1565806/1565806 [00:29<00:00, 52847.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to X-ray_dataset-1 in folder:: 100%|██████████| 56163/56163 [00:25<00:00, 2204.08it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"y9sYzOJUOLDmrFKSNJGq\")\n",
    "project = rf.workspace(\"kitsana-uyaphitang\").project(\"x-ray_dataset\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1759394863271,
     "user": {
      "displayName": "hania fatima",
      "userId": "05387605373657882009"
     },
     "user_tz": -300
    },
    "id": "eGN5burjuuX6",
    "outputId": "5f07c489-1b21-4a55-a506-3bdc3660a305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml created at /content/X-ray_dataset-1/data.yaml\n",
      "Classes detected: ['Unlabeled', 'covid19', 'normal', 'pneumonia']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "dataset_path = \"/content/X-ray_dataset-1\"\n",
    "\n",
    "\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "val_path = os.path.join(dataset_path, \"valid\")\n",
    "\n",
    "\n",
    "class_names = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
    "class_names.sort()\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    'path': dataset_path,\n",
    "    'train': 'train',\n",
    "    'val': 'valid',\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "\n",
    "yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "\n",
    "\n",
    "with open(yaml_path, 'w') as file:\n",
    "    yaml.dump(data_dict, file, sort_keys=False)\n",
    "\n",
    "print(f\"data.yaml created at {yaml_path}\")\n",
    "print(\"Classes detected:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14723829,
     "status": "ok",
     "timestamp": 1759409587104,
     "user": {
      "displayName": "hania fatima",
      "userId": "05387605373657882009"
     },
     "user_tz": -300
    },
    "id": "7n443tscu1Fk",
    "outputId": "93751e2f-78de-4b34-c222-d80720218b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.204-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.204-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.204 ultralytics-thop-2.0.17\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt': 100% ━━━━━━━━━━━━ 5.3MB 107.8MB/s 0.0s\n",
      "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/X-ray_dataset-1, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/X-ray_dataset-1/train... found 53664 images in 4 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/X-ray_dataset-1/valid... found 2039 images in 4 classes ✅ \n",
      "ERROR ❌ \u001b[34m\u001b[1mtest:\u001b[0m /content/X-ray_dataset-1/test... found 444 images in 3 classes (requires 4 classes, not 3)\n",
      "Overriding model.yaml nc=1000 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,443,412 parameters, 1,443,412 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 759.1±405.4 MB/s, size: 28.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/X-ray_dataset-1/train... 53664 images, 0 corrupt: 100% ━━━━━━━━━━━━ 53664/53664 4.7Kit/s 11.3s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/X-ray_dataset-1/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1113.8±424.2 MB/s, size: 36.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/X-ray_dataset-1/valid... 2039 images, 0 corrupt: 100% ━━━━━━━━━━━━ 2039/2039 4.8Kit/s 0.4s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/X-ray_dataset-1/valid.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/content/runs/classify/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 4.9MB/s 0.2s\n",
      "\u001b[K        1/5         0G     0.3773         16        224: 100% ━━━━━━━━━━━━ 3354/3354 1.1it/s 49:31\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 64/64 1.5it/s 43.0s\n",
      "                   all      0.947          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K        2/5         0G     0.1937         16        224: 100% ━━━━━━━━━━━━ 3354/3354 1.2it/s 47:51\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 64/64 1.3it/s 50.5s\n",
      "                   all      0.949          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K        3/5         0G     0.1629         16        224: 100% ━━━━━━━━━━━━ 3354/3354 1.2it/s 47:48\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 64/64 1.4it/s 44.7s\n",
      "                   all      0.965          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K        4/5         0G     0.1343         16        224: 100% ━━━━━━━━━━━━ 3354/3354 1.2it/s 47:06\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 64/64 1.4it/s 44.7s\n",
      "                   all      0.963          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K        5/5         0G    0.09998         16        224: 100% ━━━━━━━━━━━━ 3354/3354 1.2it/s 47:48\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 64/64 1.4it/s 47.4s\n",
      "                   all       0.97          1\n",
      "\n",
      "5 epochs completed in 4.065 hours.\n",
      "Optimizer stripped from /content/runs/classify/train/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /content/runs/classify/train/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /content/runs/classify/train/weights/best.pt...\n",
      "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,440,004 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/X-ray_dataset-1/train... found 53664 images in 4 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/X-ray_dataset-1/valid... found 2039 images in 4 classes ✅ \n",
      "ERROR ❌ \u001b[34m\u001b[1mtest:\u001b[0m /content/X-ray_dataset-1/test... found 444 images in 3 classes (requires 4 classes, not 3)\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 64/64 1.5it/s 43.4s\n",
      "                   all       0.97          1\n",
      "Speed: 0.0ms preprocess, 13.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/content/runs/classify/train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7918cb358980>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9850416779518127\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9700833559036255, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9850416779518127}\n",
       "save_dir: PosixPath('/content/runs/classify/train')\n",
       "speed: {'preprocess': 0.0010894467908827508, 'inference': 13.222901549782366, 'loss': 5.4368810901359405e-05, 'postprocess': 0.00011003874073021093}\n",
       "task: 'classify'\n",
       "top1: 0.9700833559036255\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-cls.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"/content/X-ray_dataset-1\",\n",
    "    epochs=5,\n",
    "    batch=16,\n",
    "    imgsz=224\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17295,
     "status": "ok",
     "timestamp": 1759412698635,
     "user": {
      "displayName": "hania fatima",
      "userId": "05387605373657882009"
     },
     "user_tz": -300
    },
    "id": "OtB77Mu1DMrm",
    "outputId": "d8d97120-3523-40e0-9d31-edb1ae830210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected target layer: Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "✅ Found 444 test images\n",
      "✅ Processed 10/444 images (10 successful)\n",
      "✅ Processed 20/444 images (20 successful)\n",
      "✅ Processed 30/444 images (30 successful)\n",
      "✅ Processed 40/444 images (40 successful)\n",
      "✅ Processed 50/444 images (50 successful)\n",
      "✅ Processed 60/444 images (60 successful)\n",
      "✅ Processed 70/444 images (70 successful)\n",
      "✅ Processed 80/444 images (80 successful)\n",
      "✅ Processed 90/444 images (90 successful)\n",
      "✅ Processed 100/444 images (100 successful)\n",
      "✅ Processed 110/444 images (110 successful)\n",
      "✅ Processed 120/444 images (120 successful)\n",
      "✅ Processed 130/444 images (130 successful)\n",
      "✅ Processed 140/444 images (140 successful)\n",
      "✅ Processed 150/444 images (150 successful)\n",
      "✅ Processed 160/444 images (160 successful)\n",
      "✅ Processed 170/444 images (170 successful)\n",
      "✅ Processed 180/444 images (180 successful)\n",
      "✅ Processed 190/444 images (190 successful)\n",
      "✅ Processed 200/444 images (200 successful)\n",
      "✅ Processed 210/444 images (210 successful)\n",
      "✅ Processed 220/444 images (220 successful)\n",
      "✅ Processed 230/444 images (230 successful)\n",
      "✅ Processed 240/444 images (240 successful)\n",
      "✅ Processed 250/444 images (250 successful)\n",
      "✅ Processed 260/444 images (260 successful)\n",
      "✅ Processed 270/444 images (270 successful)\n",
      "✅ Processed 280/444 images (280 successful)\n",
      "✅ Processed 290/444 images (290 successful)\n",
      "✅ Processed 300/444 images (300 successful)\n",
      "✅ Processed 310/444 images (310 successful)\n",
      "✅ Processed 320/444 images (320 successful)\n",
      "✅ Processed 330/444 images (330 successful)\n",
      "✅ Processed 340/444 images (340 successful)\n",
      "✅ Processed 350/444 images (350 successful)\n",
      "✅ Processed 360/444 images (360 successful)\n",
      "✅ Processed 370/444 images (370 successful)\n",
      "✅ Processed 380/444 images (380 successful)\n",
      "✅ Processed 390/444 images (390 successful)\n",
      "✅ Processed 400/444 images (400 successful)\n",
      "✅ Processed 410/444 images (410 successful)\n",
      "✅ Processed 420/444 images (420 successful)\n",
      "✅ Processed 430/444 images (430 successful)\n",
      "✅ Processed 440/444 images (440 successful)\n",
      "\n",
      "✅✅ All Grad-CAM results saved in: /content/gradcam_results\n",
      "📊 Total images processed successfully: 444/444\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import torch.nn as nn\n",
    "\n",
    "# Paths\n",
    "input_folder = \"/content/X-ray_dataset-1/test\"\n",
    "output_folder = \"/content/gradcam_results\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "model = YOLO(\"/content/runs/classify/train/weights/best.pt\")\n",
    "torch_model = model.model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_model.to(device).eval()\n",
    "\n",
    "\n",
    "for param in torch_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "target_layer = None\n",
    "for name, module in reversed(list(torch_model.named_modules())):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        target_layer = module\n",
    "        break\n",
    "print(\" Selected target layer:\", target_layer)\n",
    "\n",
    "if target_layer is None:\n",
    "    raise ValueError(\" No Conv2d layer found in the model!\")\n",
    "\n",
    "\n",
    "cam = GradCAM(model=torch_model, target_layers=[target_layer])\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_paths.append(os.path.join(root, f))\n",
    "\n",
    "print(f\" Found {len(image_paths)} test images\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(\" No images found! Check your input folder path.\")\n",
    "    print(f\"Looking in: {input_folder}\")\n",
    "else:\n",
    "\n",
    "    success_count = 0\n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\" Could not read: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(rgb_img, (128, 128))\n",
    "            resized_float = resized.astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "            input_tensor = torch.tensor(resized_float).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "            input_tensor.requires_grad = True\n",
    "\n",
    "            # Prediction\n",
    "            preds = model.predict(img_path, imgsz=128, verbose=False)\n",
    "            pred_class = int(preds[0].probs.top1)\n",
    "            pred_label = preds[0].names[pred_class]\n",
    "            confidence = float(preds[0].probs.top1conf)\n",
    "\n",
    "            # Grad-CAM\n",
    "            grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                                targets=[ClassifierOutputTarget(pred_class)])\n",
    "            grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "            # Overlay CAM on image\n",
    "            visualization = show_cam_on_image(resized_float, grayscale_cam,\n",
    "                                             use_rgb=True, image_weight=0.5)\n",
    "\n",
    "            # Side-by-side comparison\n",
    "            original_resized = cv2.resize(rgb_img, (256, 256))\n",
    "            viz_resized = cv2.resize(visualization, (256, 256))\n",
    "            comparison = np.hstack((original_resized, viz_resized))\n",
    "\n",
    "            # Add labels\n",
    "            cv2.putText(comparison, f\"Pred: {pred_label} ({confidence:.2f})\",\n",
    "                       (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            cv2.putText(comparison, \"Original\", (10, 240),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            cv2.putText(comparison, \"Grad-CAM\", (270, 240),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "            base_name = os.path.basename(img_path)\n",
    "            save_path = os.path.join(output_folder, f\"gradcam_{idx}_{base_name}\")\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(comparison, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            success_count += 1\n",
    "\n",
    "            if (idx + 1) % 10 == 0:\n",
    "                print(f\" Processed {idx + 1}/{len(image_paths)} images ({success_count} successful)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {os.path.basename(img_path)}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n All Grad-CAM results saved in: {output_folder}\")\n",
    "    print(f\"📊 Total images processed successfully: {success_count}/{len(image_paths)}\")\n",
    "\n",
    "# Clean up\n",
    "del cam\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2G+AcQhdMmekVIlPYYLSg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
